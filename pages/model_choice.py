import streamlit as st

def show_model_choice():
    st.title("üß† Choix du Mod√®le")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("**Logistic Regression**")
        st.write("‚úì Simple")
        st.write("‚úì Interpr√©table")
        st.write("‚úó Performance limit√©e")
    
    with col2:
        st.success("**Random Forest** ‚≠ê")
        st.write("‚úì Meilleure performance")
        st.write("‚úì G√®re non-lin√©arit√©")
        st.write("‚úì Feature importance")
    
    with col3:
        st.info("**XGBoost**")
        st.write("‚úì Tr√®s performant")
        st.write("‚úó Plus complexe")
        st.write("‚úó Temps d'entra√Ænement")
    
    st.markdown("### Pourquoi Random Forest ?")
    st.markdown("""
    - G√®re bien les donn√©es non-lin√©aires
    - Robuste aux valeurs aberrantes
    - Importance des features int√©gr√©e
    - Pas de surapprentissage (avec bons param√®tres)
    - Performance √©quilibr√©e
    """)
    
    with st.expander("üíª Voir le code d'entra√Ænement"):
        st.code("""
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import pickle

# Pr√©paration des donn√©es
X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Division train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Standardisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Entra√Ænement
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42
)
model.fit(X_train_scaled, y_train)

# Sauvegarde
pickle.dump(model, open('model.pkl', 'wb'))
pickle.dump(scaler, open('scaler.pkl', 'wb'))
        """, language='python')
